1  The theoretical address space for a 32-bit process is 4 GB, but the operating system typically reserves some of that. Often, only 3 GB is left to the process as addressable virtual memory, but on some operating systems it can be as low as 2 GB. Please take the numbers mentioned in this section as generalizations and not absolutes. There are far too many platform-specific (and historically sensitive) details to get into here. is limited to 3 GB. 1  Nowadays, with the widespread availability of 64-bit operating systems, virtual memory isn’t as precious as it used to be (addressable space for virtual memory is typically 48 bits; i.e., 256 TiB). On modern desktop operating systems, the physical memory required for stack space for each thread isn’t even allocated by the OS until it is required, including stack space per thread. For example, on a modern, 64-bit Fedora 29 Linux with 8 GB memory, creating 10,000 do-nothing threads with this short snippet: `# threadmem.py` `import` ` ` `os` `from` ` ` `time` ` ` `import` ` ` `sleep` `from` ` ` `threading` ` ` `import` ` ` `Thread` `threads` ` ` `=` ` ` `[` `  ` `Thread` `(` `target` `=` `lambda` `:` ` ` `sleep` `(` `60` `))` ` ` `for` ` ` `i` ` ` `in` ` ` `range` `(` `10000` `)` `]` `[` `t` `.` `start` `()` ` ` `for` ` ` `t` ` ` `in` ` ` `threads` `]` `print` `(` `f` `'PID = {os.getpid()}'` `)` `[` `t` `.` `join` `()` ` ` `for` ` ` `t` ` ` `in` ` ` `threads` `]` leads to the following information in  `top` : `MiB Mem : 7858.199 total, 1063.844 free, 4900.477 used` `MiB Swap: 7935.996 total, 4780.934 free, 3155.062 used` `  PID USER` `PR  NI    VIRT    RES    SHR COMMAND` `15166 caleb     20   0 80.291g 131.1m   4.8m python3` Preallocated virtual memory is a staggering ~80 GB (due to 8 MB stack space per   thread!), but resident memory is only ~130 MB . On a 32 bit  Linux system, I   would be unable to create this many because of the 3 GB  user-space addressspace limit,  *regardless*  of actual consumption of physical memory. To get around   this problem on 32-bit systems, it is sometimes necessary to decrease the   preconfigured stack size, which you can still do in Python today, with   `threading.stack_size([size])` . Obviously, decreasing stack size has implications for runtime safety with respect to the degree to which function calls may be   nested, including recursion. Single-threaded coroutines have none of these problems and are a far superior alternative for concurrent I/O. *Threading* * can * *affect* * throughput* At very high concurrency levels (say, >5,000 threads), there can also be an impact on throughput due to  context-switching  costs, assuming you can figure out how to configure your operating system to even allow you to create that many **12 ** **| ** **Chapter 2: The Truth About Threads**