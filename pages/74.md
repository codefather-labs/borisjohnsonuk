Regenerating Grammar 2,16-2,17: RPAR ')' 2,17-2,18: COLON ':' 2,18-2,19: NEWLINE '\n' 3,0-3,3: INDENT ' ' 3,3-3,7: NAME 'proceed' 3,7-3,8: NEWLINE '\n' 4,0-4,0: DEDENT '' 4,0-4,0: ENDMARKER '' In the output, the ﬁrst column is the range of the line/column coordinates, the second column is the name of the token, and the ﬁnal column is the value of the token. In the output, the  tokenize  module has implied some tokens: • The  ENCODING  token for  utf-8 • A blank line at the end • A  DEDENT  to close the function declaration • An  ENDMARKER  to end the ﬁle It is best practice to have a blank line at the end of your Python source ﬁles. If you omit it, CPython adds it for you. The  tokenize  module is written in pure Python and is located in  Lib tokenize.py . To see a verbose readout of the C tokenizer, you can run Python with the  -d  flag. Using the  test_tokens.py  script you created earlier, run it with the following: $ ./python -d test_tokens.py Token NAME/'def' ... It's a keyword DFA 'file_input', state 0: Push 'stmt' DFA 'stmt', state 0: Push 'compound_stmt' ... Token NEWLINE/'' ... It's a token we know 74