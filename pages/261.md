Multithreading member that multiprocessing has an overhead for starting the new processes, threading does have an overhead, but it is much smaller. You may be wondering- if the GIL means that only a single operation can execute at once, why is this faster? The statement that takes 1-1000ms is: result  =  sock.connect_ex((host, port)) In the C extension module,  Modules socketmodule.c , the function that implements the connection is: Modules socketmodule.c  line 3246 static int internal_connect(PySocketSockObject *s,  struct  sockaddr *addr,  int  addrlen, int  raise) { int  res, err, wait_connect; Py_BEGIN_ALLOW_THREADS res = connect(s->sock_fd, addr, addrlen); Py_END_ALLOW_THREADS Surrounding the system  connect()  call are the  Py_BEGIN_ALLOW_THREADS and  Py_END_ALLOW_THREADS  macros. These macros are deÔ¨Åned in  Include ceval.h  as: #define Py_BEGIN_ALLOW_THREADS { PyThreadState *_save; _save = PyEval_SaveThread(); #define Py_BLOCK_THREADS PyEval_RestoreThread(_save); #define Py_UNBLOCK_THREADS _save = PyEval_SaveThread(); #define Py_END_ALLOW_THREADS PyEval_RestoreThread(_save); } So, when  Py_BEGIN_ALLOW_THREADS  is called, it calls  PyEval_SaveThread() . This function changes the thread state to  NULL  and  drops  the GIL: 261