Conclusion t.start() threads.append(t) for  t  in  threads: t.join() while not  results.empty(): print( "Port  {0}  is open" .format(results.get())) print( "Completed scan in  {0}  seconds" .format(time.time()  -  start)) Because of the reduced overheads compared with multiprocessing, this example should execute 30-40% faster and with fewer memory resources: $ python portscanner_subinterpreters.py Port 80 is open Completed scan in 1.3474230766296387 seconds 
#Conclusion 

 Congratulations on getting through the biggest chapter in the book! You’ve covered a lot of ground. Let us recap some of the concepts and their applications. For truly  parallel execution , you need multiple CPUs or cores. You also need to use either  multiprocessing  or  subinterpreters  packages so that the Python interpreter can be executed in parallel. Remember that startup time is signiﬁcant, and each interpreter has a big memory overhead. If the tasks that you want to execute are shortlived, use a pool of workers and a queue of tasks. If you have multiple IO-bound tasks and want them to run  concurrently , you should use multithreading, or use coroutines with the asyncio  package. All four of these approaches require an understanding of how to safely and eﬃciently transfer data between processes or threads. The best way to reinforce what you’ve learned is to look at an application you’ve written and seen how it can be refactored to leverage these techniques. 286