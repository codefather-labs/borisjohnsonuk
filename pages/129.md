We expect that the first time we retrieve our record, there’s going to be a cache miss, and the second time, a hit. We can see evidence of this in the log for the API server itself (the first Sanic web server, running on  *localhost:8000* ): `$ sanic_demo.py` `2019-09-29 16:20:33 - (sanic)[DEBUG]:` `                 ▄▄▄▄▄` `        ▄▄▄██████▄▄▄       _______________` `      ▄▄▄▄▄  █████████▄  /                 \` `     ▄▄▄▄█████▄ ▄▄▄ ▄▄█ |   Gotta go fast!  |` `   ▄▄█████▄▄ ▄██████▄██ | _________________/` `   ▄▄▄▄▄▄  ▄▄█▄▄█════█▄ |/` `        ▄▄▄▄  ▄▄███ ▄       ▄▄` `     ▄███▄▄██▄████████▄ ▄▄▄▄▄▄▄█▄` `   ██▄▄▄▄██▄▄███▄ ▄▄████      ▄██` `▄▄▄▄▄██▄▄▄▄████▒▒▒▒▒▒███     ▄▄▄▄` `▄    ▄▄████▄███▒▒▒▒▒▄██▄` `▄▄▄▄▄▄   ▄▄████▒▒▒▒▄██▄` `          ▄▄█████████▄` `        ▄▄██▄██████▄█` `      ▄██▄     ▄▄▄  █` `     ▄█             ▄▄` ` ▄▄▄▄█▄              ▄█▄▄▄▄▄▄▄` `▄     ▄                ▄▄▄▄▄▄` ` ▄▄▄▄▄` `2019-09-29 16:20:33 (sanic): Goin' Fast @ http://0.0.0.0:8000` `2019-09-29 16:20:33 (sanic): Starting worker [10366]  ` `2019-09-29 16:25:27 (perf): id=37 Cache miss  ` `2019-09-29 16:25:27 (perf): get Elapsed: 4.26 ms ` `2019-09-29 16:25:27 (perf): get Elapsed: 0.04 ms ` Everything up to this line is the default  `sanic`  startup log message. As described, the first  `GET`  results in a cache miss because the server has only just started. This is from our first  `curl -X GET` . I’ve added some timing functionality to the API endpoints. Here we can see that the handler for the  `GET`  request took ~4 ms. The second  `GET`  returns data from the cache, and the much faster (100x faster!) timing data. So far, nothing unusual. Many web apps use caching in this way. Now let’s start up a second app instance on port 8001 (the first instance was on port 8000): `$ ` `sanic_demo.py --port 8001` `<snip>` **118 ** **| ** **Chapter 4: 20 Asyncio Libraries You Aren’t Using (But…Oh, Never Mind)**