Since all the  `news_fetch()`  tasks are now complete, we collect all of the results into a dictionary. Note how nested comprehensions are used to iterate over tasks, and then over the list of tuples returned by each task. We also use  *f-strings*  to substitute data directly, including even the kind of page, which will be used in CSS to color the  `div`  background. In this dictionary, the  *key*  is the headline title, and the  *value*  is an HTML string for a  `div`  that will be displayed in our result page. Our web server is going to return HTML. We’re loading HTML data from a local file called  *index.html* . This file is presented in  Example B-1  if you want to recreate the case study yourself. We substitute the collected headline  `div`  into the template and return the page to the browser client. This generates the page shown in  Figure 4-1 . Here, inside the  `news_fetch()`  coroutine function, we have a tiny template for hitting the Splash API (which, for me, is running in a local Docker container on port 8050). This demonstrates how  `aiohttp`  can be used as an HTTP client. The standard way is to create a  `ClientSession()`  instance, and then use the `get()`  method on the session instance to perform the REST call. In the next line, the response data is obtained. Note that because we’re always operating on coroutines, with  `async with`  and  `await` , this coroutine will never block: we’ll be able to handle many thousands of these requests, even though this operation ( `news_fetch()` ) might be relatively slow since we’re doing web calls internally. After the data is obtained, we call the postprocessing function. For CNN, it’ll be `cnn_articles()` , and for Al Jazeera it’ll be  `aljazeera_articles()` . We have space only for a brief look at the postprocessing. After getting the page data, we use the Beautiful Soup 4 library for extracting headlines. The  `match()`  function will return all matching tags (I’ve manually checked the HTML source of these news websites to figure out which combination of filters extracts the best tags), and then we return a list of tuples matching the format `<article URL>` ,  `<article title>` . This is the analogous postprocessor for Al Jazeera. The  `match()`  condition is slightly different, but it is otherwise the same as the CNN one. **aiohttp ** **| ** **97**