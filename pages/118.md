The support for  `asyncio`  in  `pyzmq`  allows us to  `await`  data from our connected apps. And not only that, but the incoming data will be automatically deserialized from JSON (yes, this means  `data`  is a  `dict()` ). Recall that our  `connections`  set holds a queue for every connected web client. Now that data has been received, it’s time to send it to all the clients: the data is placed onto each queue. The  `feed()`  coroutine function will create coroutines for each connected web client. Internally,  server-sent events  are used to push data to the web clients. As described earlier, each web client will have its own  `queue`  instance, in order to receive data from the  `collector()`  coroutine. The  `queue`  instance is added to the `connections`  set, but because  `connections`  is a  *weak*  set, the entry will automatically be removed from  `connections`  when the  `queue`  goes out of scope—i.e., when a web client disconnects.  Weakrefs  are great for simplifying these kinds of bookkeeping tasks. The  `aiohttp_sse`  package provides the  `sse_response()`  context manager. This gives us a scope inside which to push data to the web client. We remain connected to the web client, and wait for data on this specific client’s queue. As soon as the data comes in (inside  `collector()` ), it will be sent to the connected web client. Note that I reserialize the  `data`  dict here. An optimization to this code would be to avoid deserializing JSON in  `collector()` , and instead use `sock.recv_string()`  to avoid the serialization round trip. Of course, in a real scenario, you might want to deserialize in the collector, and perform some validation on the data before sending it to the browser client. So many choices! The  `index()`  endpoint is the primary page load, and here we serve a static file called  *charts.html* . The  `aiohttp`  library provides facilities for us to hook in additional long-lived coroutines we might need. With the  `collector()`  coroutine, we have exactly that situation, so I create a startup coroutine,  `start_collector()` , and a shutdown coroutine. These will be called during specific phases of  `aiohttp` ’s startup and shutdown sequence. Note that I add the collector task to the  `app`  itself, which implements a mapping protocol so that you can use it like a dict. **ØMQ (ZeroMQ) ** **| ** **107**