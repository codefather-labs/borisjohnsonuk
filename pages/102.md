The CPython Parser-Tokenizer [ 4 ,  '' ], [ 0 ,  '' ]] To make it easier to understand, you can take all the numbers in the symbol  and  token  modules, put them into a dictionary and recursively replace the values in the output of  parser.st2list()  with the names of the tokens: cpython-book-samples 21 lex.py import  symbol import  token import  parser def  lex(expression): symbols  =  {v: k  for  k, v  in  symbol.__dict__.items() if  isinstance(v, int)} tokens  =  {v: k  for  k, v  in  token.__dict__.items() if  isinstance(v, int)} lexicon  =  { ** symbols,  ** tokens} st  =  parser.expr(expression) st_list  =  parser.st2list(st) def  replace(l: list): r  =  [] for  i  in  l: if  isinstance(i, list): r.append(replace(i)) else : if  i  in  lexicon: r.append(lexicon[i]) else : r.append(i) return  r return  replace(st_list) You can run  lex()  with a simple expression, like  a + 1  to see how this is represented as a parser-tree: 102