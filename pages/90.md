followed by a message containing the data. Our broker will send such data messages to every client subscribed to that channel name. Add the  `StreamWriter`  instance to the global collection of subscribers. An infinite loop, waiting for data from this client. The first message from a client must be the destination channel name. Next comes the actual data to distribute to the channel. Get the deque of subscribers on the target channel. Some special handling if the channel name begins with the magic word  `/queue` : in this case, we send the data to  *only one*  of the subscribers, not all of them. This can be used for sharing work between a bunch of workers, rather than the usual pub-sub notification scheme, where all subscribers on a channel get all the messages. Here is why we use a deque and not a list: rotation of the deque is how we keep track of which client is next in line for  `/queue`  distribution. This seems expensive until you realize that a single deque rotation is an O(1) operation. Target only whichever client is first; this changes after every rotation. Create a list of coroutines for sending the message to each writer, and then unpack these into  `gather()`  so we can wait for all of the sending to complete. This line is a bad flaw in our program, but it may not be obvious why: though it may be true that all of the sending to each subscriber will happen concurrently, what happens if we have one very slow client? In this case, the  `gather()`  will finish only when the slowest subscriber has received its data. We can’t receive any more data from the sending client until all these  `send_msg()`  coroutines finish. This slows all message distribution to the speed of the slowest subscriber. When leaving the  `client()`  coroutine, we make sure to remove ourselves from the global  `SUBSCRIBERS`  collection. Unfortunately, this is an O( *n* ) operation, which can be a little expensive for very large  *n* . A different data structure would fix this, but for now we console ourselves with the knowledge that connections are intended to be long-lived—thus, there should be few disconnection events— and  *n*  is unlikely to be very large (say ~10,000 as a rough order-of-magnitude estimate), and this code is at least easy to understand. **Streams (Standard Library) ** **| ** **79**