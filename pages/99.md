The CPython Parser-Tokenizer CPython has a Parser/Tokenizer module, written in C. 
##Related Source Files 

 The source ﬁles relating to the parser-tokenizer are: File Purpose Python pythonrun.c Executes the parser and the compiler from an input Parser parsetok.c The Parser and Tokenizer implementation Parser tokenizer.c Tokenizer implementation Parser tokenizer.h Header ﬁle for the Tokenizer Implementation, describes data models like token state Include token.h Declaration of token types, generated by  Tools scripts generate_token.py Include node.h Parse tree node interface and macros for the tokenizer 
##Inputting Data Into the Parser From a File 

 The entry point for the parser-tokenizer,  PyParser_ASTFromFileObject() , takes a ﬁle handle, compiler flags and a  PyArena  instance and converts the ﬁle object into a module. There are two steps: 1. Convert to a CST using  PyParser_ParseFileObject() 2. Convert into a AST/module, using the AST function  PyAST_- FromNodeObject() The  PyParser_ParseFileObject()  function has two important tasks: 1. Instantiate a tokenizer state  tok_state  using  PyTokenizer_FromFile() 2. Convert the tokens into a CST (a list of  node ) using  parsetok() 
##Parser-Tokenizer Flow 

 The parser-tokenizer takes text input and executes the tokenizer and parser in a loop until the cursor is at the end of the text (or a syntax error occurred). 99