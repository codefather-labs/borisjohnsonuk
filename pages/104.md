#### Case Study: Hello World
 Example 4-13  shows a minimal web server using  `aiohttp` . *Example 4-13. Minimal aiohttp example* `from` ` ` `aiohttp` ` ` `import` ` ` `web` `async` ` ` `def` ` ` `hello` `(` `request` `):` `    ` `return` ` ` `web` `.` `Response` `(` `text` `=` `"Hello, world"` `)` `app` ` ` `=` ` ` `web` `.` `Application` `()` `  ` `app` `.` `router` `.` `add_get` `(` `'/'` `,` ` ` `hello` `)` `  ` `web` `.` `run_app` `(` `app` `,` ` ` `port` `=` `8080` `)` `  ` An  `Application`  instance is created. A route is created, with the target coroutine  `hello()`  given as the handler. The web application is run. Observe that there is no mention of loops, tasks, or futures in this code: the developers of the  `aiohttp`  framework have hidden all that away from us, leaving a very clean API. This is going to be common in most frameworks that build on top of  `asyncio` , which has been designed to allow framework designers to choose only the bits they need, and encapsulate them in their preferred API. #### Case Study: Scraping the News
 `aiohttp`  can be used both as a server and a client library, like the very popular (but blocking!)  `requests`  library. I wanted to showcase  `aiohttp`  by using an example that incorporates both features. In this case study, we’ll implement a website that does web scraping behind the scenes. The application will scrape two news websites and combine the headlines into one page of results. Here is the strategy: 1.  A browser client makes a web request to  *http://localhost:8080/news* . 2.  Our web server receives the request, and then on the backend fetches HTML data from multiple news websites. 3.  Each page’s data is scraped for headlines. 4.  The headlines are sorted and formatted into the response HTML that we send back to the browser client. Figure 4-1  shows the output. **aiohttp ** **| ** **93**